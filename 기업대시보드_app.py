import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import StringIO, BytesIO
import FinanceDataReader as fdr
import requests
from bs4 import BeautifulSoup
import urllib.request
import urllib.parse
import json
import datetime
import re
import time
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import mean_absolute_error
import zipfile
import xml.etree.ElementTree as ET
import os
import openai
import ta
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error
import hashlib
from functools import lru_cache
import concurrent.futures
import matplotlib
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.utils import ImageReader
import platform
import matplotlib.dates as mdates
from openai import OpenAI
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
import matplotlib.font_manager as fm

# --- matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ---
# Windows í™˜ê²½ì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Windows':
    # ì—¬ëŸ¬ í•œê¸€ í°íŠ¸ ì˜µì…˜ ì‹œë„
    font_options = ['Malgun Gothic', 'NanumGothic', 'NanumBarunGothic', 'Dotum', 'Batang']
    font_found = False
    
    for font_name in font_options:
        try:
            plt.rcParams['font.family'] = font_name
            # í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ í°íŠ¸ í™•ì¸
            fig, ax = plt.subplots(figsize=(1, 1))
            ax.text(0.5, 0.5, 'í…ŒìŠ¤íŠ¸', fontsize=12)
            plt.close(fig)
            font_found = True
            break
        except:
            continue
    
    if not font_found:
        # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ì„¤ì •
        plt.rcParams['font.family'] = 'DejaVu Sans'
else:
    # Linux/Mac í™˜ê²½
    plt.rcParams['font.family'] = 'DejaVu Sans'

plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# --- í† ìŠ¤ ìŠ¤íƒ€ì¼ CSS ---
st.markdown('''
    <style>
    html, body, [class*="css"]  {
        font-family: 'Pretendard', 'NanumGothic', 'Apple SD Gothic Neo', 'sans-serif';
        background-color: #f7fafd;
    }
    .stApp {
        background-color: #f7fafd;
    }
    .toss-card {
        background: white;
        border-radius: 18px;
        box-shadow: 0 2px 12px 0 rgba(0,0,0,0.04);
        padding: 2rem 1.5rem 1.5rem 1.5rem;
        margin-bottom: 1.5rem;
    }
    .toss-title {
        color: #0064ff;
        font-weight: 700;
        font-size: 1.3rem;
        margin-bottom: 0.7rem;
    }
    .toss-sub {
        color: #222;
        font-size: 1.05rem;
        margin-bottom: 0.5rem;
    }
    /* ë‰´ìŠ¤ í…Œì´ë¸” ìŠ¤íƒ€ì¼ ìˆ˜ì • */
    table {
        width: 100%;
        border-collapse: collapse;
        margin: 1rem 0;
        background-color: white;
        border-radius: 8px;
        overflow: hidden;
        font-size: 0.9rem;
    }
    th {
        background-color: #f0f4f8;
        padding: 12px 15px;
        text-align: left;
        font-weight: 600;
        color: #1a1a1a;
        border-bottom: 1px solid #e0e0e0;
        white-space: nowrap;
    }
    td {
        padding: 10px 15px;
        border-bottom: 1px solid #e0e0e0;
        color: #333;
        line-height: 1.4;
    }
    /* ê°ì • ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì • */
    th:nth-child(2), td:nth-child(2) {
        min-width: 60px;
        max-width: 60px;
    }
    /* ë‚ ì§œ ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì • */
    th:nth-child(4), td:nth-child(4) {
        min-width: 90px;
        max-width: 90px;
        white-space: nowrap;
    }
    /* ë¶„ì„ ê²°ê³¼ ìŠ¤íƒ€ì¼ */
    .analysis-result {
        background-color: #f8fafc;
        padding: 15px 20px;
        border-radius: 8px;
        margin-top: 15px;
        color: #333;
        font-size: 0.95rem;
        line-height: 1.5;
    }
    .analysis-highlight {
        color: #0064ff;
        font-weight: 500;
    }
    tr:hover {
        background-color: #f8fafc;
    }
    a {
        color: #0064ff;
        text-decoration: none;
        font-weight: 500;
    }
    a:hover {
        text-decoration: underline;
    }
    /* ê°ì •ë¶„ì„ ìš”ì•½ ìŠ¤íƒ€ì¼ */
    .sentiment-summary {
        display: flex;
        gap: 20px;
        margin-top: 15px;
        padding: 15px;
        background: #f8fafc;
        border-radius: 8px;
    }
    .sentiment-item {
        flex: 1;
        text-align: center;
    }
    .sentiment-value {
        font-size: 1.5rem;
        font-weight: 600;
        color: #0064ff;
    }
    .sentiment-label {
        font-size: 0.9rem;
        color: #666;
        margin-top: 5px;
    }
    </style>
''', unsafe_allow_html=True)

# --- í•¨ìˆ˜: ì¢…ëª©ì½”ë“œ ì¡°íšŒ ---
def get_stock_code_by_name(name):
    krx_list = fdr.StockListing('KRX')
    match = krx_list[krx_list['Name'] == name]
    if match.empty:
        return None
    return match['Code'].values[0]

# --- í•¨ìˆ˜: ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ê°ì •ë¶„ì„ ---
def fetch_naver_news(company_name, max_results=50):
    client_id = st.secrets["naver_client_id"] if "naver_client_id" in st.secrets else ""
    client_secret = st.secrets["naver_client_secret"] if "naver_client_secret" in st.secrets else ""
    query = urllib.parse.quote(company_name)
    base_url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    collected = []
    for start in range(1, 1000, 100):
        if len(collected) >= max_results:
            break
        url = f"{base_url}?query={query}&display=100&start={start}&sort=date"
        req = urllib.request.Request(url, headers=headers)
        res = urllib.request.urlopen(req)
        if res.getcode() == 200:
            data = json.loads(res.read().decode('utf-8'))
            items = data.get('items', [])
            for item in items:
                title_raw = item['title']
                title_text = re.sub(r"<.*?>", "", title_raw)
                link = item['link']
                pub_date = datetime.datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S %z')
                now = datetime.datetime.now(datetime.timezone.utc)
                if (
                    company_name in title_text and
                    "news.naver.com" in link and
                    (now - pub_date).days <= 5 * 365
                ):
                    collected.append({
                        "ì œëª©": title_text,
                        "URL": link,
                        "ë‚ ì§œ": pub_date.strftime('%Y-%m-%d')
                    })
                if len(collected) >= max_results:
                    break
    return pd.DataFrame(collected)

def crawl_naver_article(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        content_tag = soup.select_one("div#newsct_article")
        if not content_tag:
            return None
        content = content_tag.get_text(strip=True).replace("\n", " ")
        return content
    except:
        return None

def analyze_sentiment_gpt(title, content):
    client = openai.OpenAI(api_key=st.secrets["openai_api_key"])
    prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: {title}
ë³¸ë¬¸: {content[:1000]}  # ë³¸ë¬¸ ê¸¸ì´ ì œí•œ

í˜•ì‹:
ê°ì •: (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)
ì´ìœ : (í•œ ë¬¸ì¥ìœ¼ë¡œ)
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # GPT-4ì—ì„œ ë³€ê²½
        messages=[
            {"role": "system", "content": "ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()

def parse_gpt_result(text):
    # ê°ì •ê³¼ ì´ìœ ê°€ í•œ ì¤„ì— ìˆì„ ë•Œë„ ë¶„ë¦¬
    sentiment_match = re.search(r"ê°ì •\s*[:ï¼š]?\s*(ê¸ì •|ì¤‘ë¦½|ë¶€ì •)", text)
    reason_match = re.search(r"ì´ìœ \s*[:ï¼š]?\s*([^\n]*)", text)
    if not sentiment_match and "ê°ì •:" in text:
        # ê°ì •:ê¸ì • ì´ìœ :~~~ í•œ ì¤„ ì¼€ì´ìŠ¤
        m = re.match(r"ê°ì •\s*[:ï¼š]?\s*(ê¸ì •|ì¤‘ë¦½|ë¶€ì •)\s*ì´ìœ \s*[:ï¼š]?\s*(.*)", text)
        if m:
            return m.group(1).strip(), m.group(2).strip()
    sentiment = sentiment_match.group(1).strip() if sentiment_match else "ë¶„ë¥˜ ì‹¤íŒ¨"
    reason = reason_match.group(1).strip() if reason_match else text.strip()
    return sentiment, reason

# DART API ê¸°ë°˜ ìµœì‹  ì¬ë¬´ì •ë³´ ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

def safe_get(url, max_retries=3, sleep_time=1.0):
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return response
        except Exception as e:
            time.sleep(sleep_time)
    return None

def get_corp_code_dict(api_key):
    url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={api_key}"
    response = requests.get(url)
    with open("corp_code.zip", "wb") as f:
        f.write(response.content)
    with zipfile.ZipFile("corp_code.zip", "r") as zip_ref:
        zip_ref.extractall(".")
    tree = ET.parse("CORPCODE.xml")
    root = tree.getroot()
    corp_dict = {}
    for child in root.findall('list'):
        corp_name = child.find('corp_name').text.strip()
        stock_code = child.find('stock_code').text.strip()
        corp_code = child.find('corp_code').text.strip()
        if stock_code:
            corp_dict[stock_code] = (corp_code, corp_name)
    return corp_dict

def get_financials_by_stock_code(stock_code, start_year=2017, end_year=None):
    api_key = st.secrets["dart_api_key"]
    if end_year is None:
        end_year = datetime.datetime.now().year
    corp_code_dict = get_corp_code_dict(api_key)
    corp_info = corp_code_dict.get(stock_code)
    if not corp_info:
        st.error(f"[ì˜¤ë¥˜] ì¢…ëª©ì½”ë“œ '{stock_code}'ì— í•´ë‹¹í•˜ëŠ” ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    corp_code, corp_name = corp_info
    reprt_codes = {'Q1': '11013', 'Q2': '11012', 'Q3': '11014', 'Q4': '11011'}
    target_accounts = [
        'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„',
        'ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°',
        'ìœ ë™ë¶€ì±„', 'ë¹„ìœ ë™ë¶€ì±„',
        'ìë³¸ê¸ˆ', 'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ'
    ]
    all_data = []
    current_year = pd.Timestamp.today().year
    current_month = pd.Timestamp.today().month
    for year in range(start_year, end_year + 1):
        for quarter, reprt_code in reprt_codes.items():
            # ë¯¸ë˜ ë¶„ê¸° ë°ì´í„°ëŠ” ìŠ¤í‚µ
            if year == current_year and ((quarter == 'Q2' and current_month < 6) or
                                          (quarter == 'Q3' and current_month < 9) or
                                          (quarter == 'Q4' and current_month < 12)):
                continue
            url = f"https://opendart.fss.or.kr/api/fnlttSinglAcnt.json?crtfc_key={api_key}&corp_code={corp_code}&bsns_year={year}&reprt_code={reprt_code}"
            response = safe_get(url)
            if not response:
                continue
            res = response.json()
            if 'list' not in res or res.get('status') != '000':
                continue
            df = pd.DataFrame(res['list'])
            df = df[df['account_nm'].isin(target_accounts)]
            df = df[['account_nm', 'thstrm_amount']]
            df['year'] = year
            df['quarter'] = quarter
            all_data.append(df)
            time.sleep(0.7)
    if not all_data:
        st.error("ìœ íš¨í•œ ì¬ë¬´ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    final_df = pd.concat(all_data)
    final_df = final_df.pivot_table(index=['year', 'quarter'], columns='account_nm', values='thstrm_amount', aggfunc='first').reset_index()
    return final_df, corp_name

# --- í•¨ìˆ˜: ë§¤ì¶œì•¡ ì˜ˆì¸¡ (RandomForest) ---
def sales_forecast_pipeline(df):
    """
    ì…ë ¥ëœ ì¬ë¬´ ë°ì´í„°í”„ë ˆì„(df)ë¡œ ë‹¤ìŒ ë¶„ê¸° ë§¤ì¶œì•¡ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    RandomForest ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ì˜ˆì¸¡ê°’, MAE, í•™ìŠµëœ ëª¨ë¸, íŠ¹ì„± ë°ì´í„°(X)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì„±(í”¼ì²˜)ì™€ íƒ€ê²Ÿ(ë§¤ì¶œì•¡) ì„¤ì •
    df = df.copy()
    df['y'] = df['ë§¤ì¶œì•¡'].shift(-1)
    features = ['ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ë§¤ì¶œì•¡']
    X = df[features][:-1]
    y = df['y'][:-1]
    # ë°ì´í„° ë¶„í•  (í•™ìŠµ/í…ŒìŠ¤íŠ¸)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    # ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    # í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° MAE ê³„ì‚°
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    # ë‹¤ìŒ ë¶„ê¸° ì˜ˆì¸¡
    next_pred = model.predict([X.iloc[-1]])[0]
    return next_pred, mae, model, X

# --- í•¨ìˆ˜: ì£¼ê°€ ì˜ˆì¸¡ (LSTM & LightGBM) ---
def prepare_data_for_prediction(df, lookback=10):
    """ì£¼ê°€ ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    df = df.copy()
    
    # ê¸°ë³¸ ì´ë™í‰ê· ì„ 
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # ë³¼ë¦°ì € ë°´ë“œ
    df['BB_mid'] = df['Close'].rolling(window=20).mean()
    bb_std = df['Close'].rolling(window=20).std()
    df['BB_up'] = df['BB_mid'] + (bb_std * 2)
    df['BB_low'] = df['BB_mid'] - (bb_std * 2)
    
    # ê±°ë˜ëŸ‰ ì§€í‘œ
    df['Volume_MA5'] = df['Volume'].rolling(window=5).mean()
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.dropna().reset_index(drop=True)
    
    return df

def lstm_predict(df, lookback=10, epochs=50):
    df = prepare_data_for_prediction(df)
    features = ['Close', 'Volume', 'MA5', 'MA20', 'RSI', 'BB_up', 'BB_mid', 'BB_low', 'Volume_MA5']
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df[features])
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(scaled_data)):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i, 0])  # Close price
    X, y = np.array(X), np.array(y)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    train_size = int(len(X) * 0.8)
    X_train = X[:train_size]
    y_train = y[:train_size]
    
    # ëª¨ë¸ êµ¬ì„±
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(lookback, len(features))),
        LSTM(50),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ
    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)
    
    # ì˜ˆì¸¡
    predictions = []
    last_sequence = scaled_data[len(scaled_data)-lookback:]
    
    for _ in range(len(X)):
        next_pred = model.predict(last_sequence.reshape(1, lookback, len(features)))
        predictions.append(next_pred[0, 0])
        last_sequence = np.roll(last_sequence, -1, axis=0)
        last_sequence[-1, 0] = next_pred[0, 0]
    
    # ì˜ˆì¸¡ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    pred_scaled = np.zeros((len(predictions), len(features)))
    pred_scaled[:, 0] = predictions
    predictions = scaler.inverse_transform(pred_scaled)[:, 0]
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df_result = df.iloc[lookback:].copy()
    df_result['Predicted_LSTM'] = predictions
    
    rmse = np.sqrt(mean_squared_error(df_result['Close'], df_result['Predicted_LSTM']))
    return df_result, rmse

def lightgbm_predict(df):
    """LightGBM ëª¨ë¸ì„ ì‚¬ìš©í•œ ì£¼ê°€ ì˜ˆì¸¡"""
    # ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
    df = prepare_data_for_prediction(df)  # ì „ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ ì¶”ê°€
    
    # í•™ìŠµì— ì‚¬ìš©í•  íŠ¹ì„±
    features = ['MA5', 'MA20', 'RSI', 'BB_up', 'BB_mid', 'BB_low', 'Volume_MA5']
    
    # ë°ì´í„° ë¶„í• 
    train_size = int(len(df) * 0.8)
    train_data = df[:train_size]
    test_data = df[train_size:]
    
    # ëª¨ë¸ í•™ìŠµ
    model = LGBMRegressor(n_estimators=100, learning_rate=0.1)
    model.fit(train_data[features], train_data['Close'])
    
    # ì˜ˆì¸¡
    df_pred = df.copy()
    df_pred['Predicted_LGBM'] = model.predict(df[features])
    
    # RMSE ê³„ì‚°
    rmse = np.sqrt(mean_squared_error(test_data['Close'], 
                                    df_pred.loc[test_data.index, 'Predicted_LGBM']))
    
    return df_pred, rmse

def get_naver_stock_price(code, pages=50):
    df = pd.DataFrame()
    for page in range(1, pages + 1):
        url = f"https://finance.naver.com/item/sise_day.nhn?code={code}&page={page}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        table = soup.select_one('table.type2')
        temp = pd.read_html(StringIO(str(table)), header=0)[0]
        df = pd.concat([df, temp], ignore_index=True)
    df = df.dropna()
    df['Date'] = pd.to_datetime(df['ë‚ ì§œ'])
    df['Close'] = df['ì¢…ê°€'].astype(str).str.replace(',', '').astype(float)
    df['Volume'] = df['ê±°ë˜ëŸ‰'].astype(str).str.replace(',', '').astype(float)
    df = df[['Date', 'Close', 'Volume']].sort_values(by='Date')
    return df.reset_index(drop=True)

def analyze_technical_indicators(df):
    """
    ê¸°ìˆ ì  ì§€í‘œë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì‹ í˜¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì´ë™í‰ê· ì„  ë¶„ì„
    current_price = df['Close'].iloc[-1]
    ma_20 = df['MA20'].iloc[-1]
    ma_5 = df['MA5'].iloc[-1]
    
    if current_price > ma_5 and ma_5 > ma_20:
        ma_signal = "ìƒìŠ¹ì¶”ì„¸"
    elif current_price < ma_5 and ma_5 < ma_20:
        ma_signal = "í•˜ë½ì¶”ì„¸"
    else:
        ma_signal = "íš¡ë³´ì¶”ì„¸"
    
    # RSI ë¶„ì„
    current_rsi = df['RSI'].iloc[-1]
    
    if current_rsi > 70:
        rsi_signal = "ê³¼ë§¤ìˆ˜"
    elif current_rsi < 30:
        rsi_signal = "ê³¼ë§¤ë„"
    else:
        rsi_signal = "ì¤‘ë¦½"
    
    # ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„
    current_bb_up = df['BB_up'].iloc[-1]
    current_bb_low = df['BB_low'].iloc[-1]
    
    if current_price > current_bb_up:
        bb_signal = "ê³¼ë§¤ìˆ˜"
    elif current_price < current_bb_low:
        bb_signal = "ê³¼ë§¤ë„"
    else:
        bb_signal = "ì¤‘ë¦½"
    
    # ì¢…í•© ì‹ í˜¸
    signals = {
        'MA_Signal': ma_signal,
        'RSI': rsi_signal,
        'BB': bb_signal
    }
    
    # ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ê²°ì •
    buy_signals = sum(1 for signal in [ma_signal, rsi_signal, bb_signal] 
                     if signal in ["ìƒìŠ¹ì¶”ì„¸", "ê³¼ë§¤ë„"])
    sell_signals = sum(1 for signal in [ma_signal, rsi_signal, bb_signal] 
                      if signal in ["í•˜ë½ì¶”ì„¸", "ê³¼ë§¤ìˆ˜"])
    
    if buy_signals > sell_signals:
        final_signal = "ë§¤ìˆ˜"
    elif sell_signals > buy_signals:
        final_signal = "ë§¤ë„"
    else:
        final_signal = "ê´€ë§"
    
    return signals, final_signal

def generate_gpt_summary(trends, signals, model_summary):
    """
    GPTë¥¼ ì´ìš©í•œ íˆ¬ì ë¶„ì„ ìš”ì•½ ìƒì„±
    """
    max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    for attempt in range(max_retries):
        try:
            client = OpenAI(api_key=st.secrets["openai_api_key"])
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë” ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ)
            prompt = f"""
ì£¼ì‹ ì‹œì¥ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì´ë™í‰ê· ì„ : {trends['MA_Signal']}
RSI: {trends['RSI']}
ë³¼ë¦°ì €ë°´ë“œ: {trends['BB']}
ì¢…í•©ì‹ í˜¸: {signals['final']}

ë‹¤ìŒ ìˆœì„œë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ì‹œì¥ ìƒí™© (2ë¬¸ì¥)
2. ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„ (3ë¬¸ì¥)
3. íˆ¬ì ì œì•ˆ (2ë¬¸ì¥)

ì‰½ê²Œ ì„¤ëª…í•˜ê³  ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚´ì£¼ì„¸ìš”.
"""
            
            # GPT API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ì£¼ì‹ ì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  ì™„ì „í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800,  # í† í° ìˆ˜ë¥¼ 500ì—ì„œ 800ìœ¼ë¡œ ë” ì¦ê°€
                presence_penalty=0.1,
                frequency_penalty=0.1
            )
            
            # ì‘ë‹µ ë°˜í™˜
            result = response.choices[0].message.content.strip()
            
            # ì‘ë‹µì´ ì¤‘ê°„ì— ëŠê²¼ëŠ”ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
            if result and not result.endswith(('.', '!', '?')):
                # ë¬¸ì¥ì´ ì™„ì „í•˜ì§€ ì•Šìœ¼ë©´ ì¬ì‹œë„
                if attempt < max_retries - 1:
                    time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    continue
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
                    return f"""
í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤:

ì´ë™í‰ê· ì„ ì€ {trends['MA_Signal']}ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, RSIëŠ” {trends['RSI']} ìƒíƒœì…ë‹ˆë‹¤. 
ë³¼ë¦°ì €ë°´ë“œ ê¸°ì¤€ìœ¼ë¡œëŠ” {trends['BB']} êµ¬ê°„ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.

ì¢…í•©ì ìœ¼ë¡œ {signals['final']} í¬ì§€ì…˜ì´ ê¶Œì¥ë©ë‹ˆë‹¤.
"""
            
            return result
            
        except Exception as e:
            # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            if attempt < max_retries - 1:
                time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                continue
            else:
                # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
                st.warning(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                return f"""
í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤:

ì´ë™í‰ê· ì„ ì€ {trends['MA_Signal']}ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, RSIëŠ” {trends['RSI']} ìƒíƒœì…ë‹ˆë‹¤. 
ë³¼ë¦°ì €ë°´ë“œ ê¸°ì¤€ìœ¼ë¡œëŠ” {trends['BB']} êµ¬ê°„ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.

ì¢…í•©ì ìœ¼ë¡œ {signals['final']} í¬ì§€ì…˜ì´ ê¶Œì¥ë©ë‹ˆë‹¤.
"""

# --- ìºì‹œ ì„¤ì • ---
@st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹œ
def get_stock_code_by_name_cached(name):
    return get_stock_code_by_name(name)

@st.cache_data(ttl=3600)
def get_naver_stock_price_cached(code, pages=50):
    return get_naver_stock_price(code, pages)

@st.cache_data(ttl=86400)  # 24ì‹œê°„ ìºì‹œ
def get_financials_by_stock_code_cached(stock_code, start_year=2017, end_year=None):
    return get_financials_by_stock_code(stock_code, start_year, end_year)

def get_company_info(corp_code, stock_code=None):
    """DART APIë¥¼ í†µí•´ ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    api_key = st.secrets["dart_api_key"]
    url = f"https://opendart.fss.or.kr/api/company.json?crtfc_key={api_key}&corp_code={corp_code}"
    
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        if data['status'] == '000':
            # ì—…ì¢… ì •ë³´ê°€ ë¹„ì–´ìˆì„ ê²½ìš° KRXì—ì„œ ê°€ì ¸ì˜¤ê¸°
            industry = data.get('induty', '').strip()
            if not industry and stock_code:
                try:
                    krx_list = fdr.StockListing('KRX')
                    # stock_codeë¡œ ê²€ìƒ‰ (corp_codeê°€ ì•„ë‹˜)
                    company_data = krx_list[krx_list['Code'] == stock_code]
                    if not company_data.empty:
                        industry = company_data['Industry'].iloc[0]
                    else:
                        industry = 'ì •ë³´ì—†ìŒ'
                except:
                    industry = 'ì •ë³´ì—†ìŒ'
            elif not industry:
                industry = 'ì •ë³´ì—†ìŒ'
            
            return {
                'íšŒì‚¬ëª…': data.get('corp_name', 'ì •ë³´ì—†ìŒ').strip(),
                'ì˜ë¬¸ëª…': data.get('corp_name_eng', 'ì •ë³´ì—†ìŒ').strip(),
                'ëŒ€í‘œì': data.get('ceo_nm', 'ì •ë³´ì—†ìŒ').strip(),
                'ì„¤ë¦½ì¼': data.get('est_dt', 'ì •ë³´ì—†ìŒ').strip(),
                'ë³¸ì‚¬ì£¼ì†Œ': data.get('adres', 'ì •ë³´ì—†ìŒ').strip(),
                'í™ˆí˜ì´ì§€': data.get('hm_url', 'ì •ë³´ì—†ìŒ').strip(),
                'ì—…ì¢…': industry,
                'ê²°ì‚°ì›”': data.get('acc_mt', 'ì •ë³´ì—†ìŒ').strip()
            }
    return None

@st.cache_data(ttl=86400)  # 24ì‹œê°„ ìºì‹œ
def get_company_info_cached(corp_code, stock_code=None):
    return get_company_info(corp_code, stock_code)

# --- ë‰´ìŠ¤ ë¶„ì„ ìµœì í™” ---
def truncate_text(text, max_length=1000):
    """í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ ì œí•œ"""
    if len(text) > max_length:
        return text[:max_length] + "..."
    return text

def analyze_news_batch(news_items, batch_size=3):  # ë°°ì¹˜ í¬ê¸°ë¥¼ 3ìœ¼ë¡œ ì¤„ì„
    results = []
    
    def process_batch(batch):
        client = openai.OpenAI(api_key=st.secrets["openai_api_key"])
        messages = []
        for item in batch:
            # ë³¸ë¬¸ì„ 1000ìë¡œ ì œí•œ
            content = truncate_text(item['content'], 1000)
            prompt = f"""
ë‰´ìŠ¤ ê¸°ì‚¬ ê°ì • ë¶„ì„:
ì œëª©: {item['ì œëª©']}
ë³¸ë¬¸ ìš”ì•½: {content}

í˜•ì‹:
ê°ì •: (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)
ì´ìœ : (í•œ ë¬¸ì¥ìœ¼ë¡œ)
"""
            messages.append({"role": "user", "content": prompt})
        
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",  # GPT-4 ëŒ€ì‹  GPT-3.5-turbo ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    *messages
                ],
                temperature=0.2
            )
            return [choice.message.content.strip() for choice in response.choices]
        except Exception as e:
            st.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return ["ê°ì •: ì¤‘ë¦½\nì´ìœ : API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ê°’"] * len(batch)

    # ë³‘ë ¬ë¡œ ë‰´ìŠ¤ ë‚´ìš© ìˆ˜ì§‘
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_url = {executor.submit(crawl_naver_article, item['URL']): item for item in news_items}
        for future in concurrent.futures.as_completed(future_to_url):
            item = future_to_url[future]
            try:
                content = future.result() or item['ì œëª©']
                item['content'] = content
            except Exception as e:
                item['content'] = item['ì œëª©']

    # ë°°ì¹˜ ì²˜ë¦¬
    for i in range(0, len(news_items), batch_size):
        batch = news_items[i:i + batch_size]
        gpt_outputs = process_batch(batch)
        
        for item, gpt_output in zip(batch, gpt_outputs):
            sentiment, reason = parse_gpt_result(gpt_output)
            results.append({
                'ì œëª©': item['ì œëª©'],
                'ê°ì •': sentiment,
                'ì´ìœ ': reason,
                'ë‚ ì§œ': item['ë‚ ì§œ']
            })
            time.sleep(0.5)  # API í˜¸ì¶œ ê°„ ê°„ê²© ì¶”ê°€
            
    return results

# --- ì£¼ê°€ ë°ì´í„° ìµœì í™” ---
def get_naver_stock_price(code, pages=50):
    df = pd.DataFrame()
    
    # ìµœê·¼ 6ê°œì›”ì¹˜ ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸°
    recent_start = pd.Timestamp.today() - pd.DateOffset(months=6)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_page = {
            executor.submit(fetch_page, code, page): page 
            for page in range(1, pages + 1)
        }
        
        for future in concurrent.futures.as_completed(future_to_page):
            try:
                temp = future.result()
                if temp is not None:
                    df = pd.concat([df, temp], ignore_index=True)
            except Exception as e:
                continue
                
    df = df.dropna()
    df['Date'] = pd.to_datetime(df['ë‚ ì§œ'])
    df['Close'] = df['ì¢…ê°€'].astype(str).str.replace(',', '').astype(float)
    df['Volume'] = df['ê±°ë˜ëŸ‰'].astype(str).str.replace(',', '').astype(float)
    
    # ìµœê·¼ 6ê°œì›” ë°ì´í„°ë§Œ í•„í„°ë§
    df = df[df['Date'] >= recent_start]
    df = df[['Date', 'Close', 'Volume']].sort_values(by='Date')
    
    return df.reset_index(drop=True)

def fetch_page(code, page):
    url = f"https://finance.naver.com/item/sise_day.nhn?code={code}&page={page}"
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        table = soup.select_one('table.type2')
        if table:
            return pd.read_html(StringIO(str(table)), header=0)[0]
    except Exception:
        return None

def generate_pdf_report(company_name, company_info, df_news_summary, financial_summary, stock_prediction_summary):
    """PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4

    # í°íŠ¸ ì„¤ì •
    if platform.system() == 'Windows':
        font_path = 'C:/Windows/Fonts/malgun.ttf'
    else:
        font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
    
    try:
        pdfmetrics.registerFont(TTFont('Malgun', font_path))
        font_name = 'Malgun'
    except:
        font_name = 'Helvetica'

    # ì œëª©
    c.setFont(font_name, 20)
    c.drawString(50, height - 50, f"{company_name} ê¸°ì—… ë¶„ì„ ë¦¬í¬íŠ¸")
    c.setFont(font_name, 10)
    c.drawString(50, height - 70, f"ìƒì„±ì¼ì: {datetime.datetime.now().strftime('%Y-%m-%d')}")

    # êµ¬ë¶„ì„ 
    c.line(50, height - 80, width - 50, height - 80)

    # ê¸°ì—… ì •ë³´
    y = height - 120
    c.setFont(font_name, 14)
    c.drawString(50, y, "1. ê¸°ì—… ì •ë³´")
    y -= 30
    c.setFont(font_name, 10)
    for key, value in company_info.items():
        if key not in ['ì˜ë¬¸ëª…', 'ê²°ì‚°ì›”']:  # ì¼ë¶€ ì •ë³´ëŠ” ì œì™¸
            c.drawString(70, y, f"{key}: {value}")
            y -= 20

    # ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½
    y -= 30
    c.setFont(font_name, 14)
    c.drawString(50, y, "2. ìµœê·¼ ë‰´ìŠ¤ ë™í–¥")
    y -= 30
    c.setFont(font_name, 10)
    c.drawString(70, y, f"ë¶„ì„ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜: {df_news_summary['total']}ê±´")
    y -= 20
    c.drawString(70, y, f"ê¸ì •: {df_news_summary['positive']}ê±´ ({df_news_summary['positive_ratio']}%)")
    y -= 20
    c.drawString(70, y, f"ì¤‘ë¦½: {df_news_summary['neutral']}ê±´ ({df_news_summary['neutral_ratio']}%)")
    y -= 20
    c.drawString(70, y, f"ë¶€ì •: {df_news_summary['negative']}ê±´ ({df_news_summary['negative_ratio']}%)")

    # ì¬ë¬´ ì •ë³´
    y -= 40
    c.setFont(font_name, 14)
    c.drawString(50, y, "3. ì¬ë¬´ ë¶„ì„")
    y -= 30
    c.setFont(font_name, 10)
    c.drawString(70, y, f"ë‹¤ìŒ ë¶„ê¸° ë§¤ì¶œì•¡ ì˜ˆì¸¡: {financial_summary['next_prediction']:.2f}ì¡°ì›")
    y -= 20
    c.drawString(70, y, f"ì „ë¶„ê¸° ëŒ€ë¹„: {financial_summary['change_rate']}")

    # ì£¼ê°€ ì˜ˆì¸¡
    y -= 40
    c.setFont(font_name, 14)
    c.drawString(50, y, "4. ì£¼ê°€ ë¶„ì„")
    y -= 30
    c.setFont(font_name, 10)
    c.drawString(70, y, f"ì˜ˆì¸¡ ëª¨ë¸: {stock_prediction_summary['better_model']}")
    y -= 20
    c.drawString(70, y, f"RMSE: {stock_prediction_summary['rmse']:.2f}")

    # AI íˆ¬ì ë¶„ì„
    y -= 40
    c.setFont(font_name, 14)
    c.drawString(50, y, "5. AI íˆ¬ì ë¶„ì„")
    y -= 30
    c.setFont(font_name, 10)
    
    # ë¬¸ìì—´ì„ ì ì ˆí•œ ê¸¸ì´ë¡œ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ì¤„ë¡œ í‘œì‹œ
    lines = [stock_prediction_summary['gpt_summary'][i:i+80] for i in range(0, len(stock_prediction_summary['gpt_summary']), 80)]
    for line in lines:
        c.drawString(70, y, line)
        y -= 20

    c.save()
    buffer.seek(0)
    return buffer

# --- í´ë˜ìŠ¤ ì •ì˜ ---
@dataclass
class JobPosting:
    """ì±„ìš© ê³µê³  ë°ì´í„° êµ¬ì¡°"""
    title: str
    company: str
    location: str
    experience: str
    source: str
    url: str
    posted_date: str
    summary: str = ""

@dataclass
class CompanyInfo:
    """ìƒì¥ì‚¬ ê¸°ë³¸ ì •ë³´"""
    company_name: str
    stock_code: str
    market: str
    sector: str
    market_cap: Optional[int]
    employee_count: Optional[int]
    revenue: Optional[int]
    listing_date: Optional[str]
    official_website: Optional[str] = None

class KoreanListedCompanies:
    """í•œêµ­ ìƒì¥ì‚¬ ì •ë³´ ê´€ë¦¬"""
    def __init__(self):
        self.companies_db = self._load_listed_companies()

    def _load_listed_companies(self) -> Dict[str, CompanyInfo]:
        """ìƒì¥ì‚¬ ì •ë³´ ë¡œë“œ"""
        companies = {
            "ì‚¼ì„±ì „ì": CompanyInfo(
                "ì‚¼ì„±ì „ì", "005930", "KOSPI", "ë°˜ë„ì²´",
                400000000, 267937, 279651000, "1975-06-11",
                "https://www.samsung.com/sec/about-us/careers/"
            ),
            "SKí•˜ì´ë‹‰ìŠ¤": CompanyInfo(
                "SKí•˜ì´ë‹‰ìŠ¤", "000660", "KOSPI", "ë°˜ë„ì²´",
                80000000, 29415, 44819000, "1996-12-26",
                "https://careers.skhynix.com/"
            ),
            "í˜„ëŒ€ìë™ì°¨": CompanyInfo(
                "í˜„ëŒ€ìë™ì°¨", "005380", "KOSPI", "ìë™ì°¨",
                30000000, 70439, 117611000, "1974-10-02",
                "https://careers.hyundai.com/"
            ),
            "ê¸°ì•„": CompanyInfo(
                "ê¸°ì•„", "000270", "KOSPI", "ìë™ì°¨",
                25000000, 52713, 89094000, "1973-07-10",
                "https://careers.kia.com/"
            ),
            "LGì—ë„ˆì§€ì†”ë£¨ì…˜": CompanyInfo(
                "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "373220", "KOSPI", "ë°°í„°ë¦¬",
                70000000, 26586, 27307000, "2022-01-27",
                "https://www.lgensol.com/careers"
            ),
            "NAVER": CompanyInfo(
                "NAVER", "035420", "KOSPI", "ì¸í„°ë„·",
                35000000, 3793, 8487000, "2002-10-29",
                "https://career.navercorp.com/"
            ),
            "ì¹´ì¹´ì˜¤": CompanyInfo(
                "ì¹´ì¹´ì˜¤", "035720", "KOSPI", "ì¸í„°ë„·",
                25000000, 4479, 6671000, "2017-07-10",
                "https://careers.kakao.com/"
            )
        }
        return companies

    def get_company_info(self, company_name: str) -> Optional[CompanyInfo]:
        return self.companies_db.get(company_name)

def generate_job_postings(company_name: str) -> List[JobPosting]:
    """ê¸°ë³¸ ì±„ìš© ì •ë³´ ìƒì„±"""
    jobs = []
    basic_positions = [
        ("ì‹ ì…ì‚¬ì› ê³µê°œì±„ìš©", "ì‹ ì…", "ë³¸ì‚¬"),
        ("ê²½ë ¥ì§ ì±„ìš©", "3ë…„ ì´ìƒ", "ì „êµ­"),
        ("ì—°êµ¬ê°œë°œì§", "ì„ì‚¬ ì´ìƒ", "ì—°êµ¬ì†Œ"),
        ("ì˜ì—…/ë§ˆì¼€íŒ…", "2ë…„ ì´ìƒ", "ì „êµ­"),
        ("IT/ê°œë°œì§", "ê²½ë ¥ë¬´ê´€", "ë³¸ì‚¬")
    ]

    for title, exp, loc in basic_positions:
        job = JobPosting(
            title=f"{company_name} {title}",
            company=company_name,
            location=loc,
            experience=exp,
            source="ì¶”ì •ì •ë³´",
            url=f"https://careers.{company_name.lower()}.com/",
            posted_date=datetime.now().strftime('%Y-%m-%d'),
            summary=f"{company_name}ì˜ ì¼ë°˜ì ì¸ ì±„ìš© í˜•íƒœ"
        )
        jobs.append(job)

    return jobs

# --- Streamlit ëŒ€ì‹œë³´ë“œ ---
st.title('ğŸ“Š ê¸°ì—… ì¢…í•© ëŒ€ì‹œë³´ë“œ')
st.markdown('<div class="toss-card"><span class="toss-title">ê¸°ì—… ë¦¬í¬íŠ¸</span><br>ì•„ë˜ì— ê¸°ì—…ëª…ì„ ì…ë ¥í•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.</div>', unsafe_allow_html=True)

with st.form(key='search_form'):
    company_name = st.text_input('ê¸°ì—…ëª… ì…ë ¥', value='ì‚¼ì„±ì „ì')
    submitted = st.form_submit_button('ë¶„ì„ ì‹œì‘')

if submitted:
    code = get_stock_code_by_name_cached(company_name)
    if not code:
        st.error('í•´ë‹¹ ê¸°ì—…ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        st.stop()

    # ê¸°ì—… ê¸°ë³¸ ì •ë³´ í‘œì‹œ
    st.markdown('<div class="toss-card"><span class="toss-title">ğŸ¢ ê¸°ì—… ì •ë³´</span>', unsafe_allow_html=True)
    
    # corp_code ê°€ì ¸ì˜¤ê¸°
    corp_dict = get_corp_code_dict(st.secrets["dart_api_key"])
    if code in corp_dict:
        corp_code = corp_dict[code][0]
        company_info = get_company_info_cached(corp_code, code)
        
        if company_info:
            # ê¸°ì—… ì •ë³´ë¥¼ 3ê°œì˜ ì—´ë¡œ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            
            card_style = '''
                padding: 15px;
                background: white;
                border-radius: 8px;
                margin: 5px;
                height: 85px;
                overflow: hidden;
            '''
            
            label_style = '''
                color: #666;
                font-size: 0.8rem;
                margin-bottom: 5px;
            '''
            
            value_style = '''
                color: #333;
                font-size: 0.95rem;
                font-weight: 500;
                overflow: hidden;
                text-overflow: ellipsis;
                display: -webkit-box;
                -webkit-line-clamp: 2;
                -webkit-box-orient: vertical;
            '''
            
            with col1:
                st.markdown(f'''
                    <div style="{card_style}">
                        <div style="{label_style}">íšŒì‚¬ëª…</div>
                        <div style="{value_style}">{company_info['íšŒì‚¬ëª…']}</div>
            </div>
                    <div style="{card_style}">
                        <div style="{label_style}">ëŒ€í‘œì</div>
                        <div style="{value_style}">{company_info['ëŒ€í‘œì']}</div>
                    </div>
                ''', unsafe_allow_html=True)
            
            with col2:
                st.markdown(f'''
                    <div style="{card_style}">
                        <div style="{label_style}">ì„¤ë¦½ì¼</div>
                        <div style="{value_style}">{company_info['ì„¤ë¦½ì¼']}</div>
                    </div>
                    <div style="{card_style}">
                        <div style="{label_style}">ì—…ì¢…</div>
                        <div style="{value_style}">{company_info['ì—…ì¢…']}</div>
                    </div>
                ''', unsafe_allow_html=True)
            
            with col3:
                st.markdown(f'''
                    <div style="{card_style}">
                        <div style="{label_style}">ë³¸ì‚¬ì£¼ì†Œ</div>
                        <div style="{value_style}">{company_info['ë³¸ì‚¬ì£¼ì†Œ']}</div>
                    </div>
                    <div style="{card_style}">
                        <div style="{label_style}">í™ˆí˜ì´ì§€</div>
                        <div style="{value_style}"><a href="{company_info['í™ˆí˜ì´ì§€']}" target="_blank" style="color: #0064ff; text-decoration: none;">{company_info['í™ˆí˜ì´ì§€'].replace('http://', '').replace('https://', '')}</a></div>
                    </div>
                ''', unsafe_allow_html=True)
        else:
            st.warning("ê¸°ì—… ê¸°ë³¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown('</div>', unsafe_allow_html=True)

    # --- ì±„ìš© ì •ë³´ ì¶”ê°€ ---
    st.markdown("### ğŸ‘¥ ì±„ìš© ì •ë³´")
    
    # ê¸°ì—… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    listed_companies = KoreanListedCompanies()
    company_info = listed_companies.get_company_info(company_name)

    if company_info:
        # ê¸°ì—… ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"""
            #### ê¸°ì—… í˜„í™©
            - ì„ì§ì› ìˆ˜: {company_info.employee_count:,}ëª…
            - ìƒì¥ì‹œì¥: {company_info.market}
            - ì—…ì¢…: {company_info.sector}
            - ìƒì¥ì¼: {company_info.listing_date}
            """)
        
        with col2:
            if company_info.official_website:
                st.markdown(f"""
                #### ì±„ìš© ì‚¬ì´íŠ¸
                ğŸ”— [ê³µì‹ ì±„ìš© í˜ì´ì§€ ë°”ë¡œê°€ê¸°]({company_info.official_website})
                """)

        # ì±„ìš© ê³µê³  í‘œì‹œ
        st.markdown("#### ìµœê·¼ ì±„ìš© ê³µê³ ")
        job_postings = generate_job_postings(company_name)
        
        # ì±„ìš© ê³µê³ ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
        for i in range(0, len(job_postings), 2):
            col1, col2 = st.columns(2)
            
            with col1:
                job = job_postings[i]
                st.markdown(f"""
                <div style="padding: 15px; background: white; border-radius: 8px; margin: 5px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
                    <div style="font-size: 1.1rem; font-weight: 600; color: #333;">{job.title}</div>
                    <div style="color: #666; margin: 8px 0;">
                        ğŸ“ {job.location} | ğŸ’¼ {job.experience}
                    </div>
                    <div style="color: #888; font-size: 0.9rem;">{job.posted_date}</div>
                </div>
                """, unsafe_allow_html=True)
            
            if i + 1 < len(job_postings):
                with col2:
                    job = job_postings[i + 1]
                    st.markdown(f"""
                    <div style="padding: 15px; background: white; border-radius: 8px; margin: 5px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
                        <div style="font-size: 1.1rem; font-weight: 600; color: #333;">{job.title}</div>
                        <div style="color: #666; margin: 8px 0;">
                            ğŸ“ {job.location} | ğŸ’¼ {job.experience}
                        </div>
                        <div style="color: #888; font-size: 0.9rem;">{job.posted_date}</div>
                    </div>
                    """, unsafe_allow_html=True)

        # ì±„ìš© í”Œë«í¼ ë§í¬
        st.markdown("""
        #### ì±„ìš© í”Œë«í¼ ë°”ë¡œê°€ê¸°
        - [ì‚¬ëŒì¸](https://www.saramin.co.kr/)
        - [ì¡ì½”ë¦¬ì•„](https://www.jobkorea.co.kr/)
        - [ì›í‹°ë“œ](https://www.wanted.co.kr/)
        """)

    else:
        st.warning("í•´ë‹¹ ê¸°ì—…ì˜ ì±„ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown('</div>', unsafe_allow_html=True)

    # --- ì¬ë¬´ì •ë³´ í‘œì‹œ ìˆ˜ì • ---
    st.markdown('<div class="toss-card"><span class="toss-title">ğŸ“‹ ìµœê·¼ ì¬ë¬´ì •ë³´</span>', unsafe_allow_html=True)
    with st.spinner('ì¬ë¬´ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
        df_fin, corp_name = get_financials_by_stock_code_cached(code)
        if df_fin is not None and not df_fin.empty:
            df_fin_sorted = df_fin.sort_values(['year', 'quarter'], ascending=[False, False]).copy()
            df_fin_sorted['year'] = df_fin_sorted['year'].astype(str).str.replace(',', '').str.extract(r'(\d{4})')[0]
            for col in df_fin_sorted.columns:
                if col not in ['year', 'quarter']:
                    df_fin_sorted[col] = df_fin_sorted[col].apply(
                        lambda x: f"{int(float(str(x).replace(',', ''))):,}" 
                        if pd.notnull(x) and str(x).replace(',', '').replace('.', '', 1).isdigit() 
                        else x
                    )
            st.write(df_fin_sorted.head(4).sort_values(['year', 'quarter'], ascending=[True, True]))
        else:
            st.warning("ì¬ë¬´ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

    # --- ë§¤ì¶œì•¡ ì˜ˆì¸¡ ---
    st.markdown('<div class="toss-card"><span class="toss-title">ğŸ“ˆ ë§¤ì¶œì•¡ ì˜ˆì¸¡</span>', unsafe_allow_html=True)

    # Q4 ë§¤ì¶œ ëˆ„ê³„ ë³´ì •
    quarter_order = ['Q1', 'Q2', 'Q3', 'Q4']
    df_fin = df_fin.sort_values(['year', 'quarter']).reset_index(drop=True)
    df_corrected = df_fin.copy()

    # ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ì»¬ëŸ¼ì„ floatìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    # (ì½¤ë§ˆê°€ í¬í•¨ëœ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜)
    feature_cols = ['ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ë§¤ì¶œì•¡']
    for col in feature_cols:
        df_corrected[col] = df_corrected[col].apply(lambda x: float(str(x).replace(',', '')) if pd.notnull(x) else x)

    # ë‹¤ìŒ ë¶„ê¸° ì •ë³´ ê³„ì‚°
    last_row = df_corrected.iloc[-1]
    last_year = int(last_row['year'])
    last_quarter = str(last_row['quarter'])
    if last_quarter == 'Q4':
        next_year = last_year + 1
        next_quarter = 'Q1'
    else:
        next_year = last_year
        next_quarter = quarter_order[quarter_order.index(last_quarter) + 1]

    # ë§¤ì¶œì•¡ ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    X = df_corrected[feature_cols].copy()
    y = df_corrected['ë§¤ì¶œì•¡'].shift(-1)  # ë‹¤ìŒ ë¶„ê¸° ë§¤ì¶œì•¡

    # NaN ì œê±°
    mask = y.notna()
    X = X[mask]
    y = y[mask]

    # ëª¨ë¸ í•™ìŠµ
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)

    # ë‹¤ìŒ ë¶„ê¸° ì˜ˆì¸¡
    next_pred = model.predict([X.iloc[-1]])[0]
    next_pred_jo = next_pred / 1e12  # ì˜ˆì¸¡ê°’ì„ ì¡°ì› ë‹¨ìœ„ë¡œ ë³€í™˜
    prev_sales = df_corrected['ë§¤ì¶œì•¡'].iloc[-1] / 1e12  # ì´ì „ ë¶„ê¸° ë§¤ì¶œì•¡ë„ ì¡°ì› ë‹¨ìœ„

    # ì¦ê°ë¥  ê³„ì‚°
    change_rate = ((next_pred_jo - prev_sales) / prev_sales) * 100
    change_text = f"{abs(change_rate):.1f}% {'ì¦ê°€' if change_rate > 0 else 'ê°ì†Œ'}"
    trend_emoji = 'â–²' if change_rate > 0 else 'â–¼'

    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f'''
            <div style="color: #666; font-size: 0.9rem;">ë‹¤ìŒë¶„ê¸° ë§¤ì¶œì•¡ ì˜ˆì¸¡ ({next_year} {next_quarter})</div>
            <div style="color: #333; font-size: 1.4rem; font-weight: 600; margin-top: 5px;">{next_pred_jo:.2f}ì¡°ì›</div>
            <div style="color: {('#0064ff' if change_rate > 0 else '#ff6b6b')}; font-size: 0.9rem; margin-top: 5px;">
                {trend_emoji} ì „ë¶„ê¸° ëŒ€ë¹„ {change_text}
            </div>
        ''', unsafe_allow_html=True)

    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ë° ì‹œê°í™”
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': importances
    })
    feature_importance_df['Importance (%)'] = (feature_importance_df['Importance'] * 100).round(2)
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)

    # í‘œì™€ ê·¸ë˜í”„ë¥¼ ê°™ì€ ì¤„ì— í‘œì‹œ (col1: í‘œ, col2: ê·¸ë˜í”„)
    col1, col2 = st.columns([1,2])
    with col1:
        st.dataframe(feature_importance_df[['Feature', 'Importance (%)']])
    with col2:
        fig, ax = plt.subplots(figsize=(6, 5))
        ax.barh(feature_importance_df['Feature'], feature_importance_df['Importance (%)'], color='cornflowerblue')
        ax.invert_yaxis()  # ê°€ì¥ ì¤‘ìš”í•œ í•­ëª©ì´ ìœ„ë¡œ ì˜¤ë„ë¡ ë’¤ì§‘ê¸°
        ax.set_title('ë§¤ì¶œ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ì¤‘ìš”ë„ (%)')
        ax.set_xlabel('ì¤‘ìš”ë„ (%)')
        ax.set_ylabel('ì¬ë¬´ í•­ëª©')
        st.pyplot(fig)

    # ê°€ì¥ ì¤‘ìš”í•œ í•­ëª© ì„¤ëª… ë¬¸êµ¬ ì¶”ê°€ (í† ìŠ¤ ìŠ¤íƒ€ì¼ ì ìš©)
    most_important = feature_importance_df.iloc[0]
    st.markdown(f'''
        <div class="analysis-result">
            ì´ë²ˆ ë¶„ê¸° ë§¤ì¶œ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤€ í•­ëª©ì€ <span class="analysis-highlight">'{most_important['Feature']}'</span>ì…ë‹ˆë‹¤.
        </div>
    ''', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

    # --- ì£¼ê°€ ì˜ˆì¸¡ ---
    st.markdown('<div class="toss-card"><span class="toss-title">ğŸ’¹ ì£¼ê°€ ì˜ˆì¸¡</span>', unsafe_allow_html=True)

    with st.spinner('ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
        # ë°ì´í„° ì¤€ë¹„
        df_stock = get_naver_stock_price(code)
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df_stock['MA5'] = df_stock['Close'].rolling(window=5).mean()
        df_stock['MA20'] = df_stock['Close'].rolling(window=20).mean()
        
        # RSI ê³„ì‚°
        delta = df_stock['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df_stock['RSI'] = 100 - (100 / (1 + rs))
        
        # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
        df_stock['BB_mid'] = df_stock['Close'].rolling(window=20).mean()
        bb_std = df_stock['Close'].rolling(window=20).std()
        df_stock['BB_up'] = df_stock['BB_mid'] + (bb_std * 2)
        df_stock['BB_low'] = df_stock['BB_mid'] - (bb_std * 2)
        
        # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
        df_stock['Volume_MA5'] = df_stock['Volume'].rolling(window=5).mean()
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        df_stock = df_stock.dropna().reset_index(drop=True)
        
        # LightGBM ì˜ˆì¸¡
        df_lgbm, rmse_lgbm = lightgbm_predict(df_stock.copy())
        
        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        fig, ax = plt.subplots(figsize=(10, 5))
        
        # ë³¼ë¦°ì € ë°´ë“œ (íšŒìƒ‰ ì˜ì—­ìœ¼ë¡œ í‘œì‹œ)
        ax.fill_between(df_stock['Date'], df_stock['BB_up'], df_stock['BB_low'], 
                       color='gray', alpha=0.2, label='ë³¼ë¦°ì €ë°´ë“œ')
        
        # ì´ë™í‰ê· ì„ 
        ax.plot(df_stock['Date'], df_stock['MA5'], 
                label='5ì¼ ì´ë™í‰ê· ', color='#ffd700', linewidth=1, linestyle='--')
        ax.plot(df_stock['Date'], df_stock['MA20'], 
                label='20ì¼ ì´ë™í‰ê· ', color='#ff8c00', linewidth=1, linestyle='--')
        
        # ì‹¤ì œ ì£¼ê°€
        ax.plot(df_stock['Date'], df_stock['Close'], 
                label='ì‹¤ì œ ì£¼ê°€', color='#0064ff', linewidth=2)
        
        # LightGBM ì˜ˆì¸¡
        ax.plot(df_lgbm['Date'], df_lgbm['Predicted_LGBM'],
                label='ì˜ˆì¸¡ ì£¼ê°€', linestyle='--', color='#ff6b6b', linewidth=1.5)
        
        # xì¶• ë‚ ì§œ í¬ë§· ì„¤ì •
        plt.gcf().autofmt_xdate()
        ax.xaxis.set_major_locator(plt.MaxNLocator(10))
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
        ax.set_facecolor('#f7fafd')
        fig.patch.set_facecolor('#f7fafd')
        ax.tick_params(colors='#222')
        ax.grid(True, alpha=0.3)
        
        # ë²”ë¡€ ìŠ¤íƒ€ì¼ë§ (2ì¤„ë¡œ í‘œì‹œ)
        ax.legend(loc='upper left', bbox_to_anchor=(0, 1.05), 
                 ncol=2, frameon=False, fontsize=8)
        
        # ì¶• ë ˆì´ë¸”
        ax.set_xlabel('ë‚ ì§œ', fontsize=10, color='#666')
        ax.set_ylabel('ì£¼ê°€ (ì›)', fontsize=10, color='#666')
        
        # ì—¬ë°± ì¡°ì •
        plt.tight_layout()
        st.pyplot(fig)
        
        # ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„
        signals, final_signal = analyze_technical_indicators(df_stock)
        
        # ê¸°ìˆ ì  ì§€í‘œ ì¹´ë“œ í‘œì‹œ (í•œ ì¤„ì— 3ê°œ)
        st.markdown('''
<div style="display: flex; justify-content: space-between; gap: 20px; margin: 20px 0;">
    <div style="flex: 1; padding: 15px; background: white; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
        <div style="font-size: 0.9rem; color: #666; margin-bottom: 8px;">ì´ë™í‰ê· ì„ </div>
        <div style="font-size: 1.2rem; color: #0064ff; font-weight: 600;">{}</div>
    </div>
    <div style="flex: 1; padding: 15px; background: white; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
        <div style="font-size: 0.9rem; color: #666; margin-bottom: 8px;">RSI</div>
        <div style="font-size: 1.2rem; color: #0064ff; font-weight: 600;">{}</div>
    </div>
    <div style="flex: 1; padding: 15px; background: white; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
        <div style="font-size: 0.9rem; color: #666; margin-bottom: 8px;">ë³¼ë¦°ì €ë°´ë“œ</div>
        <div style="font-size: 1.2rem; color: #0064ff; font-weight: 600;">{}</div>
    </div>
</div>
'''.format(signals['MA_Signal'], signals['RSI'], signals['BB']), unsafe_allow_html=True)
        
        # AI íˆ¬ì ë¶„ì„ ìš”ì•½ (ëª¨ë¸ ì„±ëŠ¥ ì œì™¸)
        summary = generate_gpt_summary(
            trends={'MA_Signal': signals['MA_Signal'], 'RSI': signals['RSI'], 'BB': signals['BB']},
            signals={'final': final_signal},
            model_summary=""  # ëª¨ë¸ ì„±ëŠ¥ ì •ë³´ ì œì™¸
        )
        st.markdown(f'''
<div class="analysis-result" style="margin-top: 20px; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 12px 0 rgba(0,0,0,0.04);">
    <div style="font-size: 1.3rem; color: #0064ff; font-weight: 700; margin-bottom: 15px;">ğŸ’¡ AI íˆ¬ì ë¶„ì„</div>
    <div style="color: #333; line-height: 1.6; font-size: 1rem;">{summary}</div>
</div>
''', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)